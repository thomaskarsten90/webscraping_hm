{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89afd986",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "809ba61b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-09T03:20:29.163925Z",
     "start_time": "2022-09-09T03:20:28.747606Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas  as pd\n",
    "import numpy   as np\n",
    "import requests\n",
    "import sqlite3\n",
    "from sqlalchemy   import create_engine\n",
    "from bs4          import BeautifulSoup\n",
    "from datetime     import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d343b99",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dedb0e4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-09T03:20:29.905093Z",
     "start_time": "2022-09-09T03:20:29.165528Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
    "\n",
    "# URL\n",
    "url = 'https://www2.hm.com/en_us/men/products/jeans.html'\n",
    "    \n",
    "# Request to URL\n",
    "page = requests.get (url, headers=headers)\n",
    "\n",
    "# Beautiful soup Object\n",
    "soup = BeautifulSoup (page.text, 'html.parser')\n",
    "\n",
    "# ====================== Product Data ============================= #\n",
    "products = soup.find ('ul', class_= 'products-listing small')\n",
    "product_list = products.find_all('article', class_='hm-product-item')\n",
    "\n",
    "# Product id\n",
    "product_id = [p.get('data-articlecode') for p in product_list]\n",
    "\n",
    "# Product Category\n",
    "product_category = [p.get('data-category') for p in product_list]\n",
    "\n",
    "# Product name\n",
    "product_list = products.find_all('a', class_='link')\n",
    "product_name = [p.get_text() for p in product_list]\n",
    "\n",
    "# Product price\n",
    "product_list = products.find_all('span', class_='price regular')\n",
    "product_price = [p.get_text() for p in product_list]\n",
    "\n",
    "data = pd.DataFrame([product_id, product_category, product_name, product_price]).T\n",
    "data.columns = ['product_id', 'product_category', 'product_name', 'product_price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e735b38",
   "metadata": {},
   "source": [
    "# Data Collection by Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e8ee56e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-09T03:21:17.815018Z",
     "start_time": "2022-09-09T03:20:29.906350Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m page \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget (url, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Beautiful Soup object\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhtml.parser\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# ======================= Product Name ====================\u001b[39;00m\n\u001b[1;32m     37\u001b[0m product_name \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msection\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct-name-price\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/bs4/__init__.py:333\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39minitialize_soup(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_feed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m     success \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/bs4/__init__.py:451\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;66;03m# Convert the document to Unicode.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendData()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/bs4/builder/_htmlparser.py:399\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    397\u001b[0m parser\u001b[38;5;241m.\u001b[39msoup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoup\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m     parser\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTMLParseError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/html/parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;124;03mas you want (may include '\\n').\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrawdata \u001b[38;5;241m+\u001b[39m data\n\u001b[0;32m--> 110\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgoahead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/html/parser.py:174\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    172\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_endtag(i)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<!--\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[0;32m--> 174\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_comment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m startswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<?\u001b[39m\u001b[38;5;124m\"\u001b[39m, i):\n\u001b[1;32m    176\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_pi(i)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Empty dataframe\n",
    "df_compositions = pd.DataFrame()\n",
    "\n",
    "# Unique columns for all products\n",
    "aux=[]\n",
    "\n",
    "df_pattern = pd.DataFrame( columns=['Art. No.', 'Composition', 'Fit'])\n",
    "for i in range (len(data)):\n",
    "    # API Requests\n",
    "    url = 'https://www2.hm.com/en_us/productpage.' + data.loc[i, 'product_id'] +'.html'\n",
    "    \n",
    "    page = requests.get (url, headers=headers)\n",
    "\n",
    "    # Beautiful Soup object\n",
    "    soup = BeautifulSoup (page.text, 'html.parser')\n",
    "\n",
    "    # ======================= Color name ================================\n",
    "    product_list = soup.find_all('a', class_= 'filter-option miniature active' ) + soup.find_all('a', class_= 'filter-option miniature' )\n",
    "    color_name = [p.get('data-color') for p in product_list]\n",
    "\n",
    "    # Product id\n",
    "    product_id = [p.get('data-articlecode') for p in product_list]\n",
    "    \n",
    "    df_color = pd.DataFrame([product_id, color_name]).T\n",
    "    df_color.columns = ['product_id', 'color_name']\n",
    "\n",
    "    for j in range(len(df_color)):\n",
    "        # API Requests\n",
    "        url = 'https://www2.hm.com/en_us/productpage.' + df_color.loc[j, 'product_id'] +'.html'\n",
    "        \n",
    "        page = requests.get (url, headers=headers)\n",
    "\n",
    "        # Beautiful Soup object\n",
    "        soup = BeautifulSoup (page.text, 'html.parser')\n",
    "        \n",
    "        # ======================= Product Name ====================\n",
    "        product_name = soup.find_all('section', class_= 'product-name-price')\n",
    "        product_name = product_name[0].get_text().split('\\n')\n",
    "        product_name = product_name[3]\n",
    "        \n",
    "        # ======================= Product Price ====================\n",
    "        product_price = soup.find_all('section', class_= 'product-name-price')\n",
    "        product_price = re.findall(r'\\d+\\.?\\d+', product_price[0].get_text())[0]\n",
    "        \n",
    "        # ======================= Composition ================================\n",
    "        product_composition_list = soup.find_all('div', class_ = 'details-attributes-list-item')\n",
    "        product_composition = [list(filter(None, p.get_text(). split('\\n'))) for p in product_composition_list ]\n",
    "\n",
    "        # Rename Dataframe\n",
    "        df_composition = pd.DataFrame(product_composition).T\n",
    "        df_composition.columns = df_composition.iloc[0]\n",
    "\n",
    "        # Delete First row\n",
    "        df_composition = df_composition.iloc[1:].fillna(method='ffill')\n",
    "\n",
    "        # Remove pocket lining, shell, lining and Pocket\n",
    "        df_composition['Composition'] = df_composition['Composition'].replace('Pocket lining: ', '', regex=True)\n",
    "        df_composition['Composition'] = df_composition['Composition'].replace('Shell: ', '', regex=True)\n",
    "        df_composition['Composition'] = df_composition['Composition'].replace('Lining: ', '', regex=True)\n",
    "        df_composition['Composition'] = df_composition['Composition'].replace('Pocket: ', '', regex=True)\n",
    "\n",
    "        # Garantee the same number of columns\n",
    "        df_composition = pd.concat([df_pattern, df_composition], axis=0)\n",
    "\n",
    "        # Selecting only the desired columns\n",
    "        df_composition = df_composition[['Art. No.', 'Fit', 'Composition']].copy()\n",
    "\n",
    "        # Rename Columns\n",
    "        df_composition.columns = ['product_id', 'fit', 'composition']\n",
    "        df_composition['product_name'] = product_name\n",
    "        df_composition['product_price'] = product_price\n",
    "\n",
    "        # Keep new columns if it shows up\n",
    "        aux = aux + df_composition.columns.tolist()\n",
    "\n",
    "        # Merge data color + decomposition\n",
    "        df_composition = pd.merge (df_composition, df_color, how= 'left', on= 'product_id')\n",
    "\n",
    "        # all products\n",
    "        df_compositions = pd.concat([df_compositions, df_composition], axis=0)\n",
    "    \n",
    "# Join showroom data + details    \n",
    "df_compositions['style_id'] = df_compositions['product_id'].apply (lambda x: x[:-3])\n",
    "df_compositions['color_id'] = df_compositions['product_id'].apply (lambda x: x[-3:])\n",
    "\n",
    "# Scrapy datetime\n",
    "df_compositions['scrapy_datetime'] = datetime.now(). strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9d48b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-02T03:38:53.151414Z",
     "start_time": "2022-09-02T03:38:53.149338Z"
    }
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf63d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-09T03:21:17.816959Z",
     "start_time": "2022-09-09T03:21:17.816949Z"
    }
   },
   "outputs": [],
   "source": [
    "# Product id\n",
    "df_data = df_compositions.dropna(subset=['product_id'])\n",
    "\n",
    "# Product name\n",
    "df_data['product_name'] = df_data['product_name'].apply(lambda x: x.replace(' ', '_'). lower())\n",
    "\n",
    "# Product_price\n",
    "df_data['product_price'] = df_data['product_price'].astype(float)\n",
    "\n",
    "# Color name\n",
    "df_data['color_name'] = df_data['color_name']. apply(lambda x: x.replace(' ', '_').replace('/', '_').lower())\n",
    "\n",
    "# Fit\n",
    "df_data['fit'] = df_data['fit']. apply(lambda x: x.replace(' ', '_'). lower())\n",
    "\n",
    "# break composition by comma\n",
    "df1 = df_data['composition'].str.split(',', expand=True).reset_index(drop=True)\n",
    "\n",
    "# cotton | polyester | spandex | lyocell | rayon | elastomultiester\n",
    "df_ref = pd.DataFrame(index=np.arange(len(df_data)), columns=['cotton', 'polyester', 'spandex'])\n",
    "\n",
    "# ===================== Composition ========================\n",
    "# ------- cotton ---------\n",
    "df_cotton_0 = df1.loc[df1[0].str.contains('Cotton', na=True), 0]\n",
    "df_cotton_0.name = 'cotton'\n",
    "\n",
    "df_cotton_1 = df1.loc[df1[1].str.contains('Cotton', na=True), 1]\n",
    "df_cotton_1.name = 'cotton'\n",
    "\n",
    "# Combaine\n",
    "df_cotton = df_cotton_0.combine_first(df_cotton_1)\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_cotton], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "# --------polyester--------\n",
    "df_polyester_0 = df1.loc[df1[0].str.contains('Polyester', na=True), 0]\n",
    "df_polyester_0.name = 'polyester'\n",
    "\n",
    "df_polyester_1 = df1.loc[df1[1].str.contains('Polyester', na=True), 1]\n",
    "df_polyester_1.name = 'polyester'\n",
    "\n",
    "# Combaine\n",
    "df_polyester = df_polyester_0.combine_first(df_polyester_1)\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_polyester], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "# --------spandex-----------\n",
    "df_spandex = df1.loc[df1[2].str.contains('Spandex', na=True), 2]\n",
    "df_spandex.name = 'spandex'\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_spandex], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "# --------lyocell--------\n",
    "df_lyocell_0 = df1.loc[df1[0].str.contains('Lyocell', na=True), 0]\n",
    "df_lyocell_0.name = 'lyocell'\n",
    "\n",
    "df_lyocell_1 = df1.loc[df1[1].str.contains('Lyocell', na=True), 1]\n",
    "df_lyocell_1.name = 'lyocell'\n",
    "\n",
    "# Combaine\n",
    "df_lyocell = df_lyocell_0.combine_first(df_lyocell_1)\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_lyocell], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "# --------rayon--------\n",
    "df_rayon_0 = df1.loc[df1[0].str.contains('Rayon', na=True), 0]\n",
    "df_rayon_0.name = 'rayon'\n",
    "\n",
    "df_rayon_1 = df1.loc[df1[2].str.contains('Rayon', na=True), 2]\n",
    "df_rayon_1.name = 'rayon'\n",
    "\n",
    "# Combaine\n",
    "df_rayon = df_rayon_0.combine_first(df_rayon_1)\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_rayon], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "# --------elastomultiester-----------\n",
    "df_elastomultiester = df1.loc[df1[1].str.contains('Elastomultiester', na=True), 1]\n",
    "df_elastomultiester.name = 'elastomultiester'\n",
    "\n",
    "df_ref = pd.concat([df_ref, df_elastomultiester], axis=1)\n",
    "df_ref = df_ref.iloc[:, ~df_ref.columns.duplicated(keep='last')]\n",
    "\n",
    "# Join of combine with product_id\n",
    "df_aux = pd.concat([df_data['product_id'].reset_index(drop=True), df_ref], axis=1)\n",
    "\n",
    "# format composition data\n",
    "df_aux['cotton'] = df_aux['cotton'].apply(lambda x: int(re.search('\\d+', x).group(0)) / 100 if pd.notnull(x)else x)\n",
    "df_aux['polyester'] = df_aux['polyester'].apply(lambda x: int(re.search('\\d+', x).group(0)) / 100 if pd.notnull(x) else x)\n",
    "df_aux['spandex'] = df_aux['spandex'].apply(lambda x: int(re.search('\\d+', x).group(0)) / 100 if pd.notnull(x) else x)\n",
    "df_aux['lyocell'] = df_aux['lyocell'].apply(lambda x: int(re.search('\\d+', x).group(0)) / 100 if pd.notnull(x) else x)\n",
    "df_aux['rayon'] = df_aux['rayon'].apply(lambda x: int(re.search('\\d+', x).group(0)) / 100 if pd.notnull(x) else x)\n",
    "df_aux['elastomultiester'] = df_aux['elastomultiester'].apply(lambda x: int(re.search('\\d+', x).group(0)) / 100 if pd.notnull(x) else x)\n",
    "\n",
    "# Final Join\n",
    "df_aux = df_aux.groupby('product_id').max().reset_index().fillna(0)\n",
    "df_data = pd.merge(df_data, df_aux, on='product_id', how='left')\n",
    "\n",
    "# Drop Columns\n",
    "df_data = df_data.drop(columns=['composition'], axis=1)\n",
    "\n",
    "# Drop Duplicates\n",
    "df_data = df_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948257d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-09T03:21:17.817642Z",
     "start_time": "2022-09-09T03:21:17.817632Z"
    }
   },
   "outputs": [],
   "source": [
    "df_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69af8eb",
   "metadata": {},
   "source": [
    "# Data Insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c7c7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-09T03:21:17.818376Z",
     "start_time": "2022-09-09T03:21:17.818366Z"
    }
   },
   "outputs": [],
   "source": [
    "data_insert = df_data[[\n",
    "    'product_id',\n",
    "    'style_id', \n",
    "    'color_id',\n",
    "    'product_name', \n",
    "    'color_name',\n",
    "    'product_price',    \n",
    "    'fit',   \n",
    "    'cotton', \n",
    "    'polyester',\n",
    "    'spandex', \n",
    "    'lyocell', \n",
    "    'rayon', \n",
    "    'elastomultiester',\n",
    "    'scrapy_datetime'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9053c1ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-09T03:21:17.819204Z",
     "start_time": "2022-09-09T03:21:17.819194Z"
    }
   },
   "outputs": [],
   "source": [
    "#query_showroom_schema = \"\"\"\n",
    "#    CREATE TABLE vitrine(\n",
    "#     product_id          TEXT,\n",
    "#     style_id            TEXT,\n",
    "#     color_id            TEXT,\n",
    "#     product_name        TEXT,\n",
    "#     color_name          TEXT,\n",
    "#     product_price       REAL,\n",
    "#     fit                 TEXT,   \n",
    "#     cotton              REAL,\n",
    "#     polyester           REAL,\n",
    "#     spandex             REAL,\n",
    "#     lyocell             REAL,\n",
    "#     rayon               REAL,\n",
    "#     elastomultiester    REAL,\n",
    "#     scrapy_datetime     TEXT\n",
    "#)\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79047a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-09T03:21:17.820055Z",
     "start_time": "2022-09-09T03:21:17.820044Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Table\n",
    "conn = sqlite3.connect ('database_hm.sqlite')\n",
    "cursor = conn.execute (query_showroom_schema)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca0856f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-09T03:21:17.820808Z",
     "start_time": "2022-09-09T03:21:17.820798Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create database connection\n",
    "conn = create_engine('sqlite:///database_hm.sqlite', echo=False)\n",
    "\n",
    "# Insert Data\n",
    "data_insert.to_sql('vitrine', con=conn, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112b6c55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-09T03:21:17.821536Z",
     "start_time": "2022-09-09T03:21:17.821526Z"
    }
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "    SELECT * FROM vitrine\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4452b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
